async function initTTML() {
  const renderDiv = document.getElementById("render-div");
  const myVideo = document.getElementById("imscVideo");
  // Track object generated by the first <track> child element
  const myTrack = myVideo.textTracks[0];
  // The source is only available from the <track> DOM element, not the object
  const ttmlUrl = myVideo.getElementsByTagName("track")[0].src;
  // The track is disabled by default, 'hidden' does not display VTT Text
  // but fires the events
  myTrack.mode = "hidden";

  const response = await fetch(ttmlUrl);
  initTrack(await response.text());

  function initTrack(text) {
    const imscDoc = imsc.fromXML(text);
    const timeEvents = imscDoc.getMediaTimeEvents();
    // Since `TextTrackCue`/`VTTCue` does not support TTML natively, we create one (empty)
    // cue per event on the timeline of the TTML document. When the cue is triggered 
    // (`enter` event), we render the TTML document corresponding to the cue time, 
    // which is called an Intermediary Synchronic Document (ISD), into `renderDiv`.
    for (let i = 0; i < timeEvents.length; i++) {
      let myCue;
      if (i < timeEvents.length - 1) {
        // We have to provide an empty string as the VTTText
        myCue = new VTTCue(timeEvents[i], timeEvents[i + 1], "");
      } else {
        // "End" time of the last "imsc event" is the end of the video
        myCue = new VTTCue(timeEvents[i], myVideo.duration, "");
      }
      myCue.addEventListener("enter", function () {
        clearSubFromScreen();
        const myIsd = imsc.generateISD(imscDoc, this.startTime);
        imsc.renderHTML(myIsd, renderDiv);
      });
      myCue.addEventListener("exit", function () {
        clearSubFromScreen();
      });
      const r = myTrack.addCue(myCue);
    }
  }

  function clearSubFromScreen() {
    const subtitleActive = renderDiv.getElementsByTagName("div")[0];
    if (subtitleActive) {
      renderDiv.removeChild(subtitleActive);
    }
  }
}

addEventListener("load", initTTML);
